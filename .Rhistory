vertex.size = 4,
vertex.color = 'red',
vertex.label.cex = .5,
vertex.label.color = 'black')
# For this part, you switch 'igraph' to 'sna' package because we are going to use
# some functions that only are available in sna package
# As a first step, create a 'sna' graph object from an 'igraph' object
sna_g <- igraph::get.adjacency(giantGraph, sparse=FALSE) %>% network::as.network.matrix()
# this detaching is a necessary step since the two packages have some same function names
# R is often confuesed
detach('package:igraph')
library(statnet)
# Compute centralities based on 'network' package
# Calculate in-degree centrality
degree(sna_g, cmode = 'indegree')
# Store the information
centralities <- data.frame('node_name' = as.character(network.vertex.names(sna_g)),
'in_degree' = degree(sna_g, cmode = 'indegree'))
# Calculate out-degree centrality and store it in the data.frame called 'centralities'
centralities$out_degree <- degree(sna_g, cmode = 'outdegree')
# Calculate betweenness centrality and store it in the data.frame called 'centralities'
centralities$betweenness <- betweenness(sna_g)
# Calculate closeness centrality and store it in the data.frame called 'centralities'
centralities$incloseness <- igraph::closeness(giantGraph, mode = 'in')
centralities$outcloseness <- igraph::closeness(giantGraph, mode = 'out')
# Calculate eigenvector centrality and store it in the data.frame called 'centralities'
centralities$eigen <- evcent(sna_g)
# Calculate Burt's network constraint and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
centralities$netconstraint <- igraph::constraint(giantGraph)
# Calculate authority and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
# 'igraph::' allows calling for any igraph function without loading the package
centralities$authority <- igraph::authority_score(giantGraph, scale = TRUE)$`vector`
# Calculate hub and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
centralities$hub <- igraph::hub_score(giantGraph, scale = TRUE)$`vector`
View(centralities)
######################################################################################
#
# Part IV: Global Network Proporties
#
######################################################################################
# If you want to go back to igraph analysis, don't forget detaching 'sna' and 'network' first
# before recalling 'igraph'
#  go back to 'igraph'
detach('package:statnet', unload = TRUE)
library(igraph)
kcore <- giantGraph %>% graph.coreness(.) ## calculate k-cores
kcore ## show the results of k-core decomposition
## Plot a graph colored by the k-core decompotion results
giantGraph %>%
plot(.,
layout = layout_with_gem(.),
# layout = layout_with_sugiyama(.),
edge.arrow.size = .3,
vertex.size = 4,
vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
vertex.label.cex = .5,
vertex.label.color = 'black',
mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
mark.shape = 1/4,
mark.col = rainbow(length(unique(graph.coreness(.))),alpha = .1),
mark.border = NA
)
# Plot the number of clusters in the graph and their size
# there are also other algorithms for this you may want to explore
# below is using Newman-Girvan Algorithm (2003)
# if communities do not make sense to you, replace with your choice
# e.g., cluster_infomap, cluster_walktrap etc.
cluster <- giantGraph %>% cluster_edge_betweenness()
## you'll see red warning messages since the edge betweennness algorithm is not designed for a directed graph
## but you'll be able to see the results anyway.
## if you want to use a more appropriate algorithm for a directed graph, try:
# cluster <- giantGraph %>% cluster_walktrap()
cluster
# modularity measure
modularity(cluster)
# Find the number of clusters
membership(cluster)   # affiliation list
length(cluster) # number of clusters
# Find the size the each cluster
# Note that communities with one node are isolates, or have only a single tie
sizes(cluster)
# Visualize clusters - that puts colored blobs around the nodes in the same community.
# You may want to remove vertex.label=NA to figure out what terms are clustered.
cluster %>% plot(.,giantGraph,
# layout = layout_with_gem(.),
layout = layout_with_fr(giantGraph),
edge.arrow.size = .3,
vertex.size = 4,
vertex.color = adjustcolor(membership(.), alpha.f = .3),
vertex.label.cex = .5,
vertex.label.color = 'black',
mark.groups = by(seq_along(membership(.)), membership(.), invisible),
mark.shape = 1/4,
mark.col = rainbow(length(.),alpha = .1),
mark.border = NA
)
# Examine the in-degree distribution
giantGraph %>% degree.distribution(.,mode="in") %>%
plot(., col = 'black', pch = 19, cex = 1.5,
main = 'In-degree Distribution',
ylab = 'Density',
xlab = 'In-degree')
# CCDF - Complementary Cumulative Distribution Function
# Plot a log-log plot of in-degree distribution
giantGraph %>%
degree.distribution(.,cumulative = TRUE,mode ='in') %>%
plot(1:(max(degree(giantGraph,mode='in'))+1),., ## since log doesn't take 0, add 1 to every degree
log='xy', type = 'l',
main = 'Log-Log Plot of In-degree',
ylab = 'CCDF',
xlab = 'In-degree')
# Fit a power law to the degree distribution
# The output of the power.law.fit() function tells us what the exponent of the power law is ($alpha)
# and the log-likelihood of the parameters used to fit the power law distribution ($logLik)
# Also, it performs a Kolmogov-Smirnov test to test whether the given degree distribution could have
# been drawn from the fitted power law distribution.
# The function thus gives us the test statistic ($KS.stat) and p-vaule ($KS.p) for that test
in_power <- giantGraph %>%
degree.distribution(., mode='in') %>%
power.law.fit(.)
in_power
# Examine the out-degree distribution
giantGraph %>% degree.distribution(.,mode="out") %>%
plot(., col = 'black', pch = 19, cex = 1.5,
main = 'Out-degree Distribution',
ylab = 'Density',
xlab = 'Out-degree')
# Plot a log-log plot
giantGraph %>%
degree.distribution(.,cumulative = TRUE,mode ='out') %>%
plot(1:(max(degree(giantGraph,mode='out'))+1), ## since log doesn't take 0, add 1 to every degree
., log='xy', type = 'l',
main = 'Log-Log Plot of Out-degree',
ylab = 'CCDF',
xlab = 'Out-degree')
# Fit a power law to the degree distribution
out_power <- giantGraph %>%
degree.distribution(., mode='out') %>%
power.law.fit(.)
# Small-world Characteristics
ntrials <- 1000 ## set a value for the repetition
cl.rg <- numeric(ntrials) ## create an estimated value holder for clustering coefficient
apl.rg <- numeric(ntrials) ## create an estimated value holder for average path length
for (i in (1:ntrials)) {
g.rg <- rewire(giantGraph, keeping_degseq(niter = 100))
cl.rg[i] <- transitivity(g.rg, type = 'average')
apl.rg[i] <- average.path.length(g.rg)
}
# plot a histogram of simulated values for clustering coefficient + the observed value
hist(cl.rg,
main = 'Histogram of Clustering Coefficient',
xlab = 'Clustering Coefficient')
par(xpd = FALSE)
# the line indicates the mean value of clustering coefficient for your network
abline(v = giantGraph %>% transitivity(., type = 'average'), col = 'red', lty = 2)
# this tests whether the observed value is statistically different from the simulated distribution
t.test(cl.rg, mu=giantGraph %>% transitivity(., type = 'average'),
alternative = 'less') ##pick either 'less' or 'greater' based on your results
# plot a histogram of simulated values for average path length + the observed value
hist(apl.rg,
main = 'Histogram of Average Path Length',
xlab = 'Average Path Length')
# the line indicates the mean value of average path length for your network
abline(v = giantGraph %>% average.path.length(), col = 'red', lty = 2)
# this tests whether the observed value is statistically different from the simulated distribution
t.test(apl.rg, mu=giantGraph %>% average.path.length(.),
alternative = 'greater') ##pick either 'less' or 'greater' based on your results
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/bg0dyt/how_is_trump_doing_as_president/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
## actor network - nodes are users who have posted comments
# create an actor network with comment text as edge attribute
actorGraph <- redditData %>% Create("actor") %>% AddText(redditData) %>% Graph
## clean up the graph data removing self-loop
edge_cleanup <- function(graph = actorGraph){
library(igraph)
df <- get.data.frame(actorGraph)
names_list <- data.frame('name' = as.character(V(actorGraph)$name),
'label' = as.character(V(actorGraph)$label))
df$from <- sapply(df$from, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
df$to <- sapply(df$to, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
nodes <- data.frame(sort(unique(c(df$from,df$to))))
links <- df[,c('from','to')]
net <- graph.data.frame(links, nodes, directed=T)
E(net)$weight <- 1
net <- igraph::simplify(net,edge.attr.comb="sum")
return(net)
}
actorGraph <- edge_cleanup()
# check if the network is directed or undirected
is.directed(actorGraph)
########################
# Check the criterion
########################
# check the size of the network
vcount(actorGraph) ## the number of nodes/actors/users
ecount(actorGraph) ## the number of edges
print("Hello, R!")
plot(1:10)
if (!"vosonSML" %in% installed.packages()) install.packages("vosonSML") ## this package is a social media data collection tool
if (!"magrittr" %in% installed.packages()) install.packages("magrittr") ## this package allows you to use so-called pipe (%>%)
if (!"igraph" %in% installed.packages()) install.packages("igraph") ## this package is a network analysis tool
if (!"statnet" %in% install.packages()) install.packages("statnet") ## this package is another popular network analysis tool
# Now run the lines below to load the packages you have installed.
# You need to load packages every time you run the script or restart R.
library(magrittr)
library(igraph)
library(vosonSML)
# To check whether your R loads these packages, run te following code
sessionInfo() ## check other attached packages. If magrittr, vosonSML, & igraph are listed there, you're ready!
twitterAuth <- Authenticate("twitter", appName = myKeys$appName, apiKey = 'KosC41og11yJiPwWTqEiN8lUw',
apiSecret = 'eS3o2Fd2lsbcuw3CUX5lSQ03JFEpUhqOvBPJDYRiAXrRCh0VdY', apiSecretaccessToken = myKeys$accessToken,
accessTokenSecret = 'AAAAAAAAAAAAAAAAAAAAANdfIwEAAAAA0gIDMg0G0%2FCuRV5nRr1J8q2oaA8%3DorjUDkr41oXcbCNmVIO1O7O1JwyPru7kFevFUmM4DSWYAzLJlg')
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/bg0dyt/how_is_trump_doing_as_president/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
## actor network - nodes are users who have posted comments
# create an actor network with comment text as edge attribute
actorGraph <- redditData %>% Create("actor") %>% AddText(redditData) %>% Graph
## clean up the graph data removing self-loop
edge_cleanup <- function(graph = actorGraph){
library(igraph)
df <- get.data.frame(actorGraph)
names_list <- data.frame('name' = as.character(V(actorGraph)$name),
'label' = as.character(V(actorGraph)$label))
df$from <- sapply(df$from, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
df$to <- sapply(df$to, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
nodes <- data.frame(sort(unique(c(df$from,df$to))))
links <- df[,c('from','to')]
net <- graph.data.frame(links, nodes, directed=T)
E(net)$weight <- 1
net <- igraph::simplify(net,edge.attr.comb="sum")
return(net)
}
actorGraph <- edge_cleanup()
# check if the network is directed or undirected
is.directed(actorGraph)
print("Hello, R!")
plot(1:10)
print("Hello, R!")
plot(1:10)
if (!"vosonSML" %in% installed.packages()) install.packages("vosonSML") ## this package is a social media data collection tool
if (!"magrittr" %in% installed.packages()) install.packages("magrittr") ## this package allows you to use so-called pipe (%>%)
if (!"igraph" %in% installed.packages()) install.packages("igraph") ## this package is a network analysis tool
if (!"statnet" %in% install.packages()) install.packages("statnet") ## this package is another popular network analysis tool
library(magrittr)
library(igraph)
library(vosonSML)
sessionInfo()
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/bg0dyt/how_is_trump_doing_as_president/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
actorGraph <- redditData %>% Create("actor") %>% AddText(redditData) %>% Graph
## clean up the graph data removing self-loop
edge_cleanup <- function(graph = actorGraph){
library(igraph)
df <- get.data.frame(actorGraph)
names_list <- data.frame('name' = as.character(V(actorGraph)$name),
'label' = as.character(V(actorGraph)$label))
df$from <- sapply(df$from, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
df$to <- sapply(df$to, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
nodes <- data.frame(sort(unique(c(df$from,df$to))))
links <- df[,c('from','to')]
net <- graph.data.frame(links, nodes, directed=T)
E(net)$weight <- 1
net <- igraph::simplify(net,edge.attr.comb="sum")
return(net)
}
actorGraph <- edge_cleanup()
# check if the network is directed or undirected
is.directed(actorGraph)
########################
# Check the criterion
########################
# check the size of the network
vcount(actorGraph) ## the number of nodes/actors/users
ecount(actorGraph) ## the number of edges
# calculate the density of the network
graph.density(actorGraph)
# The following command saves your R environment as RData
# Please submit this RData on Canvas
save.image('Lab1_Descriptive.RData')
# Next time, you'll work on the same data
# Run the following command
# Make sure that you put the RData in your working directory
load('Lab1_Descriptive.RData')
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/87vm4h/why_is_american_media_so_politically_biaspolarised/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/changemyview/comments/80r2f2/cmv_america_should_ban_all_guns/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
actorGraph <- redditData %>% Create("actor") %>% AddText(redditData) %>% Graph
## clean up the graph data removing self-loop
edge_cleanup <- function(graph = actorGraph){
library(igraph)
df <- get.data.frame(actorGraph)
names_list <- data.frame('name' = as.character(V(actorGraph)$name),
'label' = as.character(V(actorGraph)$label))
df$from <- sapply(df$from, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
df$to <- sapply(df$to, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
nodes <- data.frame(sort(unique(c(df$from,df$to))))
links <- df[,c('from','to')]
net <- graph.data.frame(links, nodes, directed=T)
E(net)$weight <- 1
net <- igraph::simplify(net,edge.attr.comb="sum")
return(net)
}
actorGraph <- edge_cleanup()
# check if the network is directed or undirected
is.directed(actorGraph)
########################
# Check the criterion
########################
# check the size of the network
vcount(actorGraph) ## the number of nodes/actors/users
ecount(actorGraph) ## the number of edges
# calculate the density of the network
graph.density(actorGraph)
# The following command saves your R environment as RData
# Please submit this RData on Canvas
save.image('Lab1_Descriptive.RData')
# Next time, you'll work on the same data
# Run the following command
# Make sure that you put the RData in your working directory
load('Lab1_Descriptive.RData')
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/bg0dyt/how_is_trump_doing_as_president/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
library(magrittr)
library(igraph)
library(vosonSML)
sessionInfo()
# collect reddit comment threads
# Replace with your list of reddit comment thread urls
myThreadUrls <- c("https://www.reddit.com/r/Ask_Politics/comments/bg0dyt/how_is_trump_doing_as_president/")
# authentication does not require credentials
redditData <- Authenticate("reddit") %>%
Collect(threadUrls = myThreadUrls, waitTime = 5)
View(redditData)
actorGraph <- redditData %>% Create("actor") %>% AddText(redditData) %>% Graph
## clean up the graph data removing self-loop
edge_cleanup <- function(graph = actorGraph){
library(igraph)
df <- get.data.frame(actorGraph)
names_list <- data.frame('name' = as.character(V(actorGraph)$name),
'label' = as.character(V(actorGraph)$label))
df$from <- sapply(df$from, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
df$to <- sapply(df$to, function(x) names_list$label[match(x,names_list$name)] %>% as.character())
nodes <- data.frame(sort(unique(c(df$from,df$to))))
links <- df[,c('from','to')]
net <- graph.data.frame(links, nodes, directed=T)
E(net)$weight <- 1
net <- igraph::simplify(net,edge.attr.comb="sum")
return(net)
}
actorGraph <- edge_cleanup()
# check if the network is directed or undirected
is.directed(actorGraph)
########################
# Check the criterion
########################
# check the size of the network
vcount(actorGraph) ## the number of nodes/actors/users
ecount(actorGraph) ## the number of edges
# calculate the density of the network
graph.density(actorGraph)
View(redditData)
View(redditData)
View(redditData)
save(redditData)
save(redditData, file= 'BOCHE_Lab1.RData')
save(redditData, file= '/Users/anuradha/Desktop/Social Networks/Lab1/BOCHE_Lab1.RData')
load("~/Desktop/Social Networks/Lab1/BOCHE_Lab1.RData")
load("~/Desktop/Social Networks/Lab1/BOCHE_Lab1.RData")
# Next time, you'll work on the same data
# Run the following command
# Make sure that you put the RData in your working directory
load('Lab1_Descriptive.RData')
redditData
# install.packages("xtable") ##this is optional - create a result table for LaTex
# install.packages("texreg") ##this is optional - create a result table
library(RSiena)
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
# install.packages("xtable") ##this is optional - create a result table for LaTex
# install.packages("texreg") ##this is optional - create a result table
library(RSiena)
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
# install.packages("xtable") ##this is optional - create a result table for LaTex
# install.packages("texreg") ##this is optional - create a result table
library(RSiena)
install.packages("xtable") ##this is optional - create a result table for LaTex
install.packages("texreg") ##this is optional - create a result table
library(RSiena)
uninstall.packages("RSiena")
remove.packages("RSiena")
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
#remove.packages("RSiena")
#install.packages("RSiena")  ## just do it one time (the first time that you run this code)
# install.packages("xtable") ##this is optional - create a result table for LaTex
# install.packages("texreg") ##this is optional - create a result table
library(RSiena)
#remove.packages("RSiena")
#install.packages("RSiena")  ## just do it one time (the first time that you run this code)
install.packages('XQuartz')
#remove.packages("RSiena")
#install.packages("RSiena")  ## just do it one time (the first time that you run this code)
install.packages("XQuartz")
install.packages("xtable") ##this is optional - create a result table for LaTex
install.packages("texreg") ##this is optional - create a result table
library(RSiena)
library(RSiena)
library(texreg)
detach("package:texreg", unload = TRUE)
remove.packages("RSiena")
library(texreg)
remove.packages("texreg")
library(xtable)
remove.packages("xtable")
#remove.packages("RSiena")
install.packages("RSiena")  ## just do it one time (the first time that you run this code)
#install.packages("XQuartz")
#install.packages("xtable") ##this is optional - create a result table for LaTex
#install.packages("texreg") ##this is optional - create a result table
library(RSiena)
#install.packages("RSiena")  ## just do it one time (the first time that you run this code)
# install.packages("xtable") ##this is optional - create a result table for LaTex
# install.packages("texreg") ##this is optional - create a result table
library(RSiena)
library(statnet)
# help !
?RSiena
?sienaNet
# -------------------------------------------------------------------------------------------------
# Set the working directory
# Session > Set Working Directory > To Source File Location
# -------------------------------------------------------------------------------------------------
list.files() # List the files in the current working directory to see if you're in the right directory
# Read in data and convert to matrix format
friend.data.w1 <- as.matrix(read.table("s50-network1.dat"))
setwd("~/Documents/GitHub/msia-490-snap-project")
# Read in data and convert to matrix format
friend.data.w1 <- as.matrix(read.table("/Users/anuradha/Documents/GitHub/msia-490-snap-project/data/edges_post.csv"))
friend.data.w2 <- as.matrix(read.table("/Users/anuradha/Documents/GitHub/msia-490-snap-project/data/edges_post.csv"))
# Read in data and convert to matrix format
post.data.w1 <- as.matrix(read.table("/Users/anuradha/Documents/GitHub/msia-490-snap-project/data/edges_post.csv"))
pre.data.w2 <- as.matrix(read.table("/Users/anuradha/Documents/GitHub/msia-490-snap-project/data/edges_post.csv"))
# outdegrees or indegrees, if there are any of such outliers.
net1 <- as.network(post.data.w1)
net2 <- as.network(pre.data.w2)
# plot sociomatrix - the filled cells indicate 1 (there is a tie), while blank cells indicate 0 (no tie)
plot.sociomatrix(net1,drawlab=F,diaglab=F,xlab='friendship t1') ##if drawlab = T, you'll see the labels of the nodes
# outdegrees or indegrees, if there are any of such outliers.
net1 <- as.network(post.data.w1)
net2 <- as.network(pre.data.w2)
# plot sociomatrix - the filled cells indicate 1 (there is a tie), while blank cells indicate 0 (no tie)
plot.sociomatrix(net1,drawlab=F,diaglab=F,xlab='friendship t1') ##if drawlab = T, you'll see the labels of the nodes
plot.sociomatrix(net2,drawlab=F,diaglab=F,xlab='friendship t2')
# plot sociomatrix - the filled cells indicate 1 (there is a tie), while blank cells indicate 0 (no tie)
plot.sociomatrix(net1,drawlab=F,diaglab=F,xlab='friendship t1') ##if drawlab = T, you'll see the labels of the nodes
# Create objects for the dependent variables.
friendship <- sienaNet(array(c(post.data.w1, pre.data.w2), dim=c(50, 50, 3)))
# Read in data and convert to matrix format
post.data.w1 <- as.matrix(read.table("/Users/anuradha/Documents/GitHub/msia-490-snap-project/data/edges_post.csv"))
print(post.data.w1)
# outdegrees or indegrees, if there are any of such outliers.
net1 <- as.network(post.data.w1)
net2 <- as.network(pre.data.w2)
#net3 <- as.network(friend.data.w3)
net1
# plot sociomatrix - the filled cells indicate 1 (there is a tie), while blank cells indicate 0 (no tie)
plot.sociomatrix(net1,drawlab=F,diaglab=F,xlab='friendship t1') ##if drawlab = T, you'll see the labels of the nodes
#net3 <- as.network(friend.data.w3)
net1
friend.data.w3 <- as.matrix(read.table("/Users/anuradha/Desktop/Social Networks/Lab3/s50-network3.dat"))
friend.data.w3
post.data.w1
View(lawn)
# Create objects for the dependent variables.
friendship <- sienaNet(array(c(pre.data.w1, post.data.w2), dim=c(50, 50, 3)))
# Create objects for the dependent variables.
friendship <- sienaNet(array(c(post.data.w1, pre.data.w2), dim=c(50, 50, 3)))
post.data.w1
